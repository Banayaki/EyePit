{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.layers import *\n",
    "from makiflow.models.segmentation.segmentator import Segmentator\n",
    "from makiflow.augmentation import AffineAugment, ElasticAugment, ImageCutter, Data\n",
    "from makiflow.save_recover import Builder\n",
    "from makiflow.trainers import SegmentatorTrainer\n",
    "import makiflow as mf\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_data='../dataset/mask'):\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "\n",
    "    masks = glob.glob(f'{path_to_data}/*.bmp')\n",
    "    for mask_name in tqdm(masks):\n",
    "        img = cv2.imread(mask_name.replace('mask', 'imgs'))\n",
    "        mask = cv2.imread(mask_name)\n",
    "        Xtrain.append(img)\n",
    "        Ytrain.append(mask)\n",
    "        \n",
    "    return Xtrain, Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_num_pos(labels):\n",
    "    area = labels[0].shape[0] * labels[0].shape[1]\n",
    "    return [area - (label == 0).sum() for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 183.12it/s]\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [ 0 10 20 30 50 60 90]\n",
      "2: [ 0 10 20 30 40 50 90]\n",
      "5: [ 0 10 20 30 40 50 60 80 90]\n",
      "6: [ 0 10 20 30 50 60 90]\n",
      "7: [ 0 10 20 30 50 60 90]\n",
      "11: [ 0 10 20 30 50 70 90]\n",
      "12: [ 0 10 20 30 50 60 90]\n",
      "13: [ 0 10 20 30 50 60 90]\n",
      "15: [ 0 10 20 30 50 60 70 90]\n",
      "17: [ 0 10 20 30 50 60 90]\n",
      "20: [ 0 10 20 30 40 50 90]\n",
      "22: [ 0 10 20 30 50 60 90]\n",
      "24: [ 0 10 20 30 50 80 90]\n",
      "26: [ 0 10 20 30 50 60 90]\n",
      "27: [ 0 10 20 30 50 60 70 90]\n",
      "28: [ 0 10 20 30 50 60 90]\n",
      "29: [ 0 10 20 30 50 60 90]\n",
      "30: [ 0 10 20 30 50 80 90]\n",
      "31: [ 0 10 20 30 50 60 90]\n",
      "32: [ 0 10 20 30 40 50 80 90]\n",
      "36: [ 0 10 20 30 50 60 80 90]\n",
      "37: [ 0 10 20 30 50 60 90]\n",
      "39: [ 0 10 20 30 50 60 90]\n",
      "41: [ 0 10 20 30 50 70 90]\n",
      "42: [ 0 10 20 30 50 60 90]\n",
      "44: [ 0 10 20 30 40 90]\n",
      "46: [ 0 10 20 30 50 60 90]\n",
      "48: [ 0 10 20 30 50 60 90]\n",
      "49: [ 0 10 20 30 50 60 90]\n",
      "50: [ 0 10 20 30 50 60 90]\n",
      "53: [ 0 10 20 30 40 50 90]\n",
      "54: [ 0 10 20 30 40 50 90]\n",
      "56: [ 0 10 20 30 40 60 80 90]\n",
      "60: [ 0 10 20 30 50 80 90]\n",
      "62: [ 0 10 20 30 50 60 90]\n",
      "63: [ 0 10 20 30 50 80 90]\n",
      "65: [ 0 10 20 30 50 60 90]\n",
      "66: [ 0 10 20 30 50 80 90]\n",
      "67: [ 0 10 20 30 50 60 80 90]\n",
      "68: [ 0 10 20 30 40 50 90]\n",
      "69: [ 0 10 20 30 50 70 90]\n",
      "70: [ 0 10 20 30 50 60 90]\n",
      "71: [ 0 10 20 30 50 60 90]\n",
      "72: [ 0 10 20 30 40 50 90]\n",
      "73: [ 0 10 20 30 50 60 90]\n",
      "75: [ 0 10 20 30 40 50 60 90]\n",
      "76: [ 0 10 20 30 50 60 90]\n",
      "79: [ 0 10 20 30 40 50 90]\n",
      "83: [ 0 10 20 30 50 60 90]\n",
      "84: [ 0 10 20 30 40 50 90]\n",
      "85: [ 0 10 20 30 50 80 90]\n",
      "86: [ 0 10 20 30 50 60 90]\n",
      "88: [ 0 10 20 30 40 50 90]\n",
      "90: [ 0 10 20 30 40 50 90]\n",
      "91: [ 0 10 20 30 50 60 90]\n",
      "92: [ 0 10 20 30 40 50 60 90]\n",
      "93: [ 0 10 20 30 60 90]\n",
      "96: [ 0 10 20 30 50 60 90]\n",
      "97: [ 0 10 20 30 50 70 80 90]\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "count = 0\n",
    "for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "    u = np.unique(lbl)\n",
    "    if 60 in u or 40 in u or 70 in u or 80 in u:\n",
    "        print(f'{i}: {u}')\n",
    "        count += 1\n",
    "        Xtest.append(img)\n",
    "        Ytest.append(lbl)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 # 4\n",
    "24 # 8\n",
    "41 # 7\n",
    "85 # 8\n",
    "75 # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    uniq = np.unique(label)\n",
    "    if i in []:\n",
    "        Xtest.append(images[i])\n",
    "        Ytest.append(label)\n",
    "    else:\n",
    "        Xtrain.append(images[i])\n",
    "        Ytrain.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Xtrain), len(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important \n",
    "25/41/14/19/43/2/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in zip(copy(Xtrain), copy(Ytrain)):\n",
    "    uniq = np.unique(label)\n",
    "    if 40 in uniq or 70 in uniq or 80 in uniq:\n",
    "        Ytrain += [label] * 10\n",
    "        Xtrain += [image] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtrain, Ytrain, _ = ImageCutter.image_and_mask_cutter(Xtrain, Ytrain, 256, 256, 128, 128, 0.5)\n",
    "Xtest, Ytest, _ = ImageCutter.image_and_mask_cutter(Xtest, Ytest, 256, 256, 128, 128, 0.5)\n",
    "print(len(Xtrain), len(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.asarray(Xtrain).astype(np.float32) / 255\n",
    "Xtrain = [i for i in Xtrain]\n",
    "Ytrain = np.asarray(Ytrain).astype(np.uint8) // 10\n",
    "Ytrain = [i for i in Ytrain]\n",
    "Xtest = np.asarray(Xtest).astype(np.float32) / 255\n",
    "Xtest = [i for i in Xtest]\n",
    "Ytest = np.asarray(Ytest).astype(np.uint8) // 10\n",
    "Ytest = [i for i in Ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(Xtrain, Ytrain)\n",
    "data = AffineAugment(num_matrices=2, noise_type='gaussian', keep_old_data=True)(data)\n",
    "data = ElasticAugment(num_maps=3, border_mode='reflect_101',  keep_old_data=True)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_images, aug_labels = data.get_data()\n",
    "print(len(aug_images))\n",
    "print(type(aug_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = [cv2.cvtColor(item, cv2.COLOR_BGR2GRAY) for item in Ytrain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_labels = [cv2.cvtColor(item, cv2.COLOR_BGR2GRAY) for item in aug_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest = [cv2.cvtColor(item, cv2.COLOR_BGR2GRAY) for item in Ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = calc_num_pos(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([i > 0 for i in num_pos]) == len(num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtest[0].shape, Ytest[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.set_main_gpu(0)\n",
    "model = Builder.segmentator_from_json('unetMobileNet/model.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_session(tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('result/Test_pretrained_Unet_with_MobileNetV2_backbone/MakiSegmentator_gamma=2.0_lr=0.001_bsz=32/last_weights/weights.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def confusion_mat(\n",
    "        p, l,\n",
    "        use_argmax_p=False, use_argmax_l=False, to_flatten=False, normalize=True,\n",
    "        save_path=None, dpi=150, annot=False):\n",
    "    \"\"\"\n",
    "    Creates confusion matrix for the given predictions `p` and labels `l`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : np.ndarray\n",
    "        Predictions.\n",
    "    l : np.ndarray\n",
    "        Corresponding labels.\n",
    "    use_argmax_p : bool\n",
    "        Set to true if prediction aren't sparse, i.e. `p` is an array of shape [..., num_classes].\n",
    "    use_argmax_l : bool\n",
    "        Set to True if labels aren't sparse (one-hot encoded), i.e. `l` is an array of shape [..., num_classes].\n",
    "    to_flatten : bool\n",
    "        Set to True if `p' and `l` are high-dimensional arrays.\n",
    "    normalize : bool \n",
    "        Set to True if you want to ge normalized matrix.\n",
    "    save_path : str\n",
    "        Saving path for the confusion matrix picture.\n",
    "    dpi : int\n",
    "        Affects the size of the saved confusion matrix picture.\n",
    "    annot : bool\n",
    "        Set to true if want to see actual numbers on the matrix picture.\n",
    "    \"\"\"\n",
    "    if use_argmax_p:\n",
    "        p = p.argmax(axis=-1)\n",
    "\n",
    "    if use_argmax_l:\n",
    "        l = l.argmax(axis=-1)\n",
    "\n",
    "    if to_flatten:\n",
    "        p = p.reshape(-1)\n",
    "        l = l.reshape(-1)\n",
    "\n",
    "    mat = np.asarray(confusion_matrix(l, p), dtype=np.float32)\n",
    "    mat /= mat.sum(axis=0)\n",
    "    mat = np.round(mat, decimals=2)\n",
    "    del p\n",
    "    del l\n",
    "\n",
    "    if save_path is not None:\n",
    "        conf_mat = sns.heatmap(mat, annot=annot)\n",
    "        conf_mat.figure.savefig(save_path, dpi=dpi)\n",
    "        plt.close(conf_mat.figure)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(Xtrain[:250]) // batch_sz\n",
    "labels = []\n",
    "predictions = []\n",
    "for i in range(n_batches):\n",
    "    labels += Ytrain[i * batch_sz: (i+1) * batch_sz]\n",
    "    predictions += [model.predict(Xtrain[i * batch_sz: (i+1) * batch_sz])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = len(Xtest) // batch_sz\n",
    "labels = []\n",
    "predictions = []\n",
    "for i in range(n_batches):\n",
    "    labels += Ytest[i * batch_sz: (i+1) * batch_sz]\n",
    "    predictions += [model.predict(Xtest[i * batch_sz: (i+1) * batch_sz])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.vstack(predictions)\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_mat(predictions, labels, use_argmax_p=True, to_flatten=True, save_path='mat.png', annot=True)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat / mat.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob('../dataset/imgs/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "class ImageCutter:\n",
    "\n",
    "    @staticmethod\n",
    "    def image_and_mask_cutter(\n",
    "        images, masks, window_h, window_w, step_x, step_y, classes_to_get,\n",
    "        use_all_px=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Crops `images` and `masks` using sliding window with resize.\n",
    "        Parameters\n",
    "        ----------\n",
    "        images : list\n",
    "            List of input images.\n",
    "        masks : list\n",
    "            List of input masks.\n",
    "        window_h : int\n",
    "            Output image height.\n",
    "        window_w : int\n",
    "            Output image width.\n",
    "        step_x : int\n",
    "            Sliding window step by OX.\n",
    "        step_y : int\n",
    "            Sliding window step by OX.\n",
    "        scale_factor : float\n",
    "            Scale factor, must be in range (0, 1). After each 'sliding window step' the original images\n",
    "            are resized to (previous_width * scale_factor, previous_height * scale_factor).\n",
    "        postprocessing : func\n",
    "            Post processing function, using on cropped image (may be function what calculate num positives pixels).\n",
    "        use_all_px : bool\n",
    "            If True, all pixels of image would be in output lists.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Three list:\n",
    "            1. cropped images\n",
    "            2. cropped masks\n",
    "            3. additional list (result of post processing)\n",
    "        \"\"\"\n",
    "        assert (len(images) > 0)\n",
    "        assert (len(images) == len(masks))\n",
    "        assert (window_h > 0 and window_w > 0 and step_x > 0 and step_y > 0)\n",
    "\n",
    "        cropped_images = []\n",
    "        cropped_masks = []\n",
    "        additional_list = []\n",
    "        dx = 0\n",
    "        dy = 0\n",
    "\n",
    "        for index, (img, mask) in enumerate(zip(images, masks)):\n",
    "            print(index)\n",
    "            assert (img.shape[:2] == mask.shape[:2])\n",
    "            current_height, current_width = img.shape[:2]\n",
    "\n",
    "\n",
    "            for dy in range(int((current_height - window_h) / step_y)):\n",
    "                for dx in range(int((current_width - window_w) / step_x)):\n",
    "                    crop_img, crop_mask = ImageCutter.crop_img_and_mask(\n",
    "                        img,\n",
    "                        mask,\n",
    "                        dy * step_y, dy * step_y + window_h, dx * step_x, dx * step_x + window_w)\n",
    "                    if ImageCutter.has_class(crop_mask, classes_to_get):\n",
    "                        cropped_images.append(crop_img)\n",
    "                        cropped_masks.append(crop_mask)\n",
    "\n",
    "            if use_all_px:\n",
    "                overlap_y = dy * step_y + window_h != current_height\n",
    "                overlap_x = dx * step_x + window_w != current_width\n",
    "                if overlap_y:\n",
    "                    for dx in range(int((current_width - window_w) / step_x)):\n",
    "                        crop_img, crop_mask = ImageCutter.crop_img_and_mask(\n",
    "                            img,\n",
    "                            mask,\n",
    "                            current_height - window_h, current_height, dx * step_x, dx * step_x + window_w)\n",
    "                        if ImageCutter.has_class(crop_mask, classes_to_get):\n",
    "                            cropped_images.append(crop_img)\n",
    "                            cropped_masks.append(crop_mask)\n",
    "\n",
    "                if overlap_x:\n",
    "                    for dy in range(int((current_height - window_h) / step_y)):\n",
    "                        crop_img, crop_mask = ImageCutter.crop_img_and_mask(\n",
    "                            img,\n",
    "                            mask,\n",
    "                            dy * step_y, dy * step_y + window_h, current_width - window_w, current_width)\n",
    "                        if ImageCutter.has_class(crop_mask, classes_to_get):\n",
    "                            cropped_images.append(crop_img)\n",
    "                            cropped_masks.append(crop_mask)\n",
    "\n",
    "                if overlap_x and overlap_y:\n",
    "                    crop_img, crop_mask = ImageCutter.crop_img_and_mask(\n",
    "                        img,\n",
    "                        mask,\n",
    "                        current_height - window_h, current_height, current_width - window_w, current_width)\n",
    "                    if ImageCutter.has_class(crop_mask, classes_to_get):\n",
    "                        cropped_images.append(crop_img)\n",
    "                        cropped_masks.append(crop_mask)\n",
    "\n",
    "        return cropped_images, cropped_masks, additional_list\n",
    "\n",
    "    @staticmethod\n",
    "    def crop_img_and_mask(img, mask, up, down, left, right):\n",
    "        crop_img = img[up: down, left: right]\n",
    "        crop_mask = mask[up: down, left: right]\n",
    "        return crop_img, crop_mask\n",
    "    \n",
    "    @staticmethod\n",
    "    def has_class(mask, needed):\n",
    "        actual = np.unique(mask)\n",
    "        for need in needed:\n",
    "            if need in actual:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lbls = [], []\n",
    "for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "    if i in [2, 24, 41, 85, 75, 6, 7]:\n",
    "        imgs += [img]\n",
    "        lbls += [lbl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 # 4\n",
    "24 # 8\n",
    "41 # 7\n",
    "85 # 8\n",
    "75 # 4\n",
    "6 # 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#imgs, lbls = load_data()\n",
    "\n",
    "cropped_images1, cropped_masks1, _ = ImageCutter.image_and_mask_cutter(\n",
    "    imgs, lbls, window_h=256, window_w=256, step_x=50, step_y=50, classes_to_get=[40, 70, 80],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#imgs, lbls = load_data()\n",
    "# 7\n",
    "cropped_images2, cropped_masks2, _ = ImageCutter.image_and_mask_cutter(\n",
    "    imgs, lbls, window_h=256, window_w=256, step_x=40, step_y=40, classes_to_get=[70],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#imgs, lbls = load_data()\n",
    "# 6\n",
    "cropped_images3, cropped_masks3, _ = ImageCutter.image_and_mask_cutter(\n",
    "    imgs, lbls, window_h=256, window_w=256, step_x=60, step_y=60, classes_to_get=[60],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#imgs, lbls = load_data()\n",
    "# 10\n",
    "cropped_images4, cropped_masks4, _ = ImageCutter.image_and_mask_cutter(\n",
    "    imgs, lbls, window_h=256, window_w=256, step_x=60, step_y=60, classes_to_get=[10],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks1):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70\n",
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks2):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60\n",
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks3):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60\n",
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks4):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks5):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks3+cropped_masks2+cropped_masks1+cropped_masks):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {i*10: 0 for i in range(10)}\n",
    "for index, mask in enumerate(cropped_masks3+cropped_masks2+cropped_masks1+cropped_masks4):\n",
    "    uniq = np.unique(mask)\n",
    "    for k in uniq:\n",
    "        class_dict[k] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 726,\n",
       " 10: 176,\n",
       " 20: 177,\n",
       " 30: 726,\n",
       " 40: 208,\n",
       " 50: 413,\n",
       " 60: 85,\n",
       " 70: 18,\n",
       " 80: 274,\n",
       " 90: 672}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "736"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropped_masks3+cropped_masks2+cropped_masks1+cropped_masks4 + cropped_masks1[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "736 % 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropped_masks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

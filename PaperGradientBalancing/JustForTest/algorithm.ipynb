{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shoto\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_csv('contest_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 0, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_num(bin_vec):\n",
    "    num = 0\n",
    "    for i in range(len(bin_vec)):\n",
    "        num += 2**i * bin_vec[i]\n",
    "    return num\n",
    "\n",
    "def get_unique(arr):\n",
    "    uniq = {}\n",
    "    uniq_vecs = []\n",
    "    for vec in arr:\n",
    "        num = to_num(vec)\n",
    "        uniq[num] = 1 + uniq.get(num, 0)\n",
    "        if uniq[num] == 1:\n",
    "            print(vec)\n",
    "    return uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 1 1 0 0 1]\n",
      "[1 1 1 1 0 1 0 0 0 1]\n",
      "[1 1 1 1 0 1 0 0 1 1]\n",
      "[1 1 1 1 1 1 1 0 1 1]\n",
      "[1 1 1 1 0 1 1 0 1 1]\n",
      "[1 1 1 1 1 1 1 0 0 1]\n",
      "[1 1 1 1 1 1 0 0 0 1]\n",
      "[1 1 1 1 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 0 1 0 1 1]\n",
      "[1 1 1 1 0 1 0 1 0 1]\n",
      "[1 1 1 1 0 0 0 0 0 1]\n",
      "[1 1 1 1 1 1 0 0 1 1]\n",
      "[1 1 1 1 0 1 0 0 0 0]\n",
      "[1 1 1 1 0 1 1 1 0 1]\n",
      "[1 1 1 1 0 0 1 0 0 1]\n",
      "[1 1 1 1 0 1 0 1 1 1]\n",
      "[1 1 1 1 1 0 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{623: 28,\n",
       " 559: 33,\n",
       " 815: 6,\n",
       " 895: 1,\n",
       " 879: 2,\n",
       " 639: 2,\n",
       " 575: 10,\n",
       " 15: 4,\n",
       " 863: 1,\n",
       " 687: 3,\n",
       " 527: 3,\n",
       " 831: 1,\n",
       " 47: 1,\n",
       " 751: 2,\n",
       " 591: 1,\n",
       " 943: 1,\n",
       " 543: 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST STAGE\n",
    "\n",
    "def first_stage(arr, filter_level):\n",
    "    percentage = arr.sum(axis=0) / len(arr)\n",
    "    return percentage < filter_level\n",
    "\n",
    "# SECOND STAGE \n",
    "\n",
    "def to_num(bin_vec):\n",
    "    num = 0\n",
    "    for i in range(len(bin_vec)):\n",
    "        num += 2**i * bin_vec[i]\n",
    "    return num\n",
    "\n",
    "def get_unique(arr):\n",
    "    uniq = {}\n",
    "    uniq_vecs = []\n",
    "    for vec in arr:\n",
    "        num = to_num(vec)\n",
    "        uniq[num] = 1 + uniq.get(num, 0)\n",
    "        if uniq[num] == 1:\n",
    "            uniq_vecs += [vec]\n",
    "    return np.array(uniq_vecs)\n",
    "\n",
    "# THIRD STAGE\n",
    "\n",
    "def dist(v1, v2):\n",
    "    diff = v1 - v2\n",
    "    return np.sqrt(diff.dot(diff))\n",
    "\n",
    "def vec_len(vec):\n",
    "    return np.sqrt(vec.dot(vec))\n",
    "\n",
    "def find_farest(main_vec, arr):\n",
    "    # Normalize main vector in order to constaint its values in the interval [0, 1]\n",
    "    main_vec_norm = main_vec.sum(axis=0) / len(main_vec)\n",
    "    farest_vec = arr[0]\n",
    "    farest_dist = dist(farest_vec, main_vec_norm)\n",
    "    for vec in arr:\n",
    "        new_dist = dist(main_vec_norm, vec)\n",
    "        if vec_len(vec) == 0:\n",
    "            continue\n",
    "        if new_dist > farest_dist:\n",
    "            farest_dist = new_dist\n",
    "            farest_vec = vec\n",
    "    return farest_vec\n",
    "\n",
    "# MAIN ALGORITHM\n",
    "\n",
    "def algorithm(arr, filter_level=0.9, iterations=10):\n",
    "    # First stage: Filter\n",
    "    # Figure out which classes actually to balance\n",
    "    to_balance = first_stage(arr, filter_level)\n",
    "    arr = arr[:, to_balance]\n",
    "    # Second stage: Picking unique vectors\n",
    "    arr = get_unique(arr)\n",
    "    print(arr)\n",
    "    # Third stage: Balancing\n",
    "    # Use euclidian distance to see how far vectors from each other.\n",
    "    # Add together the most different vectors.\n",
    "    main_vec = np.zeros(arr.shape[1])\n",
    "    for i in range(10):\n",
    "        print(find_farest(main_vec, arr))\n",
    "        main_vec += find_farest(main_vec, arr)\n",
    "        \n",
    "    return main_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [1 1 0 1]\n",
      " [0 1 0 1]\n",
      " [1 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 1]\n",
      " [0 1 1 0]\n",
      " [0 0 1 1]]\n",
      "[1 1 0 1]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n",
      "[0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1., 10.,  0.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST STAGE\n",
    "\n",
    "def first_stage(arr, filter_level):\n",
    "    percentage = arr.sum(axis=0) / len(arr)\n",
    "    return percentage < filter_level\n",
    "\n",
    "# SECOND STAGE \n",
    "\n",
    "def to_num(bin_vec):\n",
    "    num = 0\n",
    "    for i in range(len(bin_vec)):\n",
    "        num += 2**i * bin_vec[i]\n",
    "    return num\n",
    "\n",
    "def get_unique(arr):\n",
    "    uniq = {}\n",
    "    uniq_vecs = []\n",
    "    for vec in arr:\n",
    "        num = to_num(vec)\n",
    "        uniq[num] = 1 + uniq.get(num, 0)\n",
    "        if uniq[num] == 1:\n",
    "            uniq_vecs += [vec]\n",
    "    return np.array(uniq_vecs), uniq\n",
    "\n",
    "# THIRD STAGE\n",
    "\n",
    "def dist(v1, v2):\n",
    "    diff = v1 - v2\n",
    "    return np.sqrt(diff.dot(diff))\n",
    "\n",
    "def vec_len(vec):\n",
    "    return np.sqrt(vec.dot(vec))\n",
    "\n",
    "def find_best_candidate(main_vec, arr):\n",
    "    prevalent = main_vec.max()\n",
    "    hyper_pyramid = np.ones(len(main_vec)) * (prevalent + 1)\n",
    "    best_c = arr[0]\n",
    "    best_dist = dist(hyper_pyramid, arr[0] + main_vec)\n",
    "    for vec in arr:\n",
    "        new_dist = dist(hyper_pyramid, vec + main_vec)\n",
    "        #print(new_dist)\n",
    "        if new_dist < best_dist:\n",
    "            best_dist = new_dist\n",
    "            best_c = vec\n",
    "    return best_c\n",
    "\n",
    "# MAIN ALGORITHM\n",
    "\n",
    "def algorithm(arr, filter_level=0.9, iterations=10):\n",
    "    # First stage: Filter\n",
    "    # Figure out which classes actually to balance\n",
    "    to_balance = first_stage(arr, filter_level)\n",
    "    arr = arr[:, to_balance]\n",
    "    # Second stage: Picking unique vectors\n",
    "    arr, uniq = get_unique(arr)\n",
    "    print(uniq)\n",
    "    # Third stage: Balancing\n",
    "    # Use euclidian distance to see how far vectors from each other.\n",
    "    # Add together the most different vectors.\n",
    "    new_uniq = {}\n",
    "    main_vec = np.zeros(arr.shape[1])\n",
    "    for i in range(iterations):\n",
    "        num = to_num(find_best_candidate(main_vec, arr))\n",
    "        new_uniq[num] = 1 + new_uniq.get(num, 0)\n",
    "        #print(find_best_candidate(main_vec, arr))\n",
    "        main_vec += find_best_candidate(main_vec, arr)\n",
    "        \n",
    "    return main_vec / iterations, new_uniq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{623: 28, 559: 33, 815: 6, 895: 1, 879: 2, 639: 2, 575: 10, 15: 4, 863: 1, 687: 3, 527: 3, 831: 1, 47: 1, 751: 2, 591: 1, 943: 1, 543: 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1. , 1. , 1. , 1. , 0.6, 1. , 0.8, 0.4, 0.8, 1. ]),\n",
       " {895: 600, 751: 200, 943: 200})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm(arr, filter_level=1.1, iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_candidate(main_vec, arr):\n",
    "    prevalent = main_vec.max()\n",
    "    hyper_pyramid = np.ones(len(main_vec)) * (prevalent + 1)\n",
    "    best_c = arr[0]\n",
    "    best_dist = dist(hyper_pyramid, arr[0] + main_vec)\n",
    "    for vec in arr:\n",
    "        new_dist = dist(hyper_pyramid, vec + main_vec)\n",
    "        #print(new_dist)\n",
    "        if new_dist < best_dist:\n",
    "            best_dist = new_dist\n",
    "            best_c = vec\n",
    "    return best_c\n",
    "\n",
    "# MAIN ALGORITHM\n",
    "\n",
    "def algorithm(arr, filter_level=0.9, iterations=10):\n",
    "    # First stage: Filter\n",
    "    # Figure out which classes actually to balance\n",
    "    to_balance = first_stage(arr, filter_level)\n",
    "    arr = arr[:, to_balance]\n",
    "    # Second stage: Picking unique vectors\n",
    "    arr, uniq = get_unique(arr)\n",
    "    print(uniq)\n",
    "    # Third stage: Balancing\n",
    "    # Use euclidian distance to see how far vectors from each other.\n",
    "    # Add together the most different vectors.\n",
    "    new_uniq = {}\n",
    "    main_vec = np.zeros(arr.shape[1])\n",
    "    for i in range(iterations):\n",
    "        num = to_num(find_best_candidate(main_vec, arr))\n",
    "        new_uniq[num] = 1 + new_uniq.get(num, 0)\n",
    "        #print(find_best_candidate(main_vec, arr))\n",
    "        main_vec += find_best_candidate(main_vec, arr)\n",
    "        \n",
    "    return main_vec / iterations, new_uniq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

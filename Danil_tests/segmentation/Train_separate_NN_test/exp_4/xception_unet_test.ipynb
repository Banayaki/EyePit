{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from makiflow.layers import *\n",
    "from makiflow.models.segmentation.segmentator import Segmentator\n",
    "from makiflow.tf_scripts import set_main_gpu\n",
    "set_main_gpu(1)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from makiflow.models.classificator import Classificator\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def merging_masks(masks, index_of_main_mask, priority):\n",
    "    \"\"\"\n",
    "    We choose the base mask which have index `index_of_main_mask` on which is put other classes\n",
    "    according to `priority` of other classes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    masks : list or numpy.array\n",
    "        List or numpy array of masks.\n",
    "    index_of_main_mask : int\n",
    "        Index of base mask.\n",
    "    priority : list\n",
    "        List of priority of classes. From highest priority to least priority.\n",
    "        Example: [9, 10, 3, 7], where 9 class have highest priority and will be put on others classes,\n",
    "        on the other hand the 7th class have the lowest priority and will be put on the others the latest.\n",
    "    Returns\n",
    "    ---------\n",
    "    main_mask : numpy.array\n",
    "        The base mask after merging other classes.\n",
    "    \"\"\"\n",
    "\n",
    "    # For easy access\n",
    "    main_mask = copy.deepcopy(masks[index_of_main_mask])\n",
    "\n",
    "    # Thanks to the `boolean_mask` higher priority class will not be erased\n",
    "    boolean_mask = np.ones(main_mask.shape).astype(np.bool)\n",
    "\n",
    "    for i in range(len(masks)):\n",
    "        if i == index_of_main_mask:\n",
    "            continue\n",
    "\n",
    "        for prior in priority:\n",
    "            temp_bool_mask = masks[i] == prior\n",
    "            temp_bool_mask = temp_bool_mask * boolean_mask\n",
    "            main_mask[temp_bool_mask] = prior\n",
    "            boolean_mask[masks[i] == prior] = False\n",
    "        \n",
    "        print(boolean_mask[248,82])\n",
    "\n",
    "    return main_mask\n",
    "\n",
    "\n",
    "def mutate_masks(masks, mapping):\n",
    "    \"\"\"\n",
    "    Remaps classes on the given `masks` according to the `mapping`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    masks : list or numpy.array\n",
    "        List or numpy array of masks.\n",
    "    mapping : list\n",
    "        List of tuples: [(source_class_number, new_class_number)],\n",
    "        where `source_class_number` will be changed to `new_class_number` in the `masks`.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    new_masks : the same type as `masks`\n",
    "        New masks with changed class numbers.\n",
    "    \"\"\"\n",
    "    if type(mapping) is not list or (len(mapping) != 0 and type(mapping[0]) is not tuple):\n",
    "        raise TypeError('mapping should be list of typles')\n",
    "\n",
    "    new_masks = copy.deepcopy(masks)\n",
    "\n",
    "    for i in range(len(new_masks)):\n",
    "        for elem in mapping:\n",
    "            old_value = elem[0]\n",
    "            new_value = elem[1]\n",
    "            new_masks[i][masks[i] == old_value] = new_value\n",
    "\n",
    "    return  new_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.save_recover import Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    Xtrain, Ytrain = [], []\n",
    "    masks = glob.glob(path + '/masks/*.bmp')\n",
    "    masks.sort()\n",
    "    for mask_name in tqdm(masks):\n",
    "        img = cv2.imread(mask_name.replace('masks', 'images'))\n",
    "        img = cv2.resize(img, (1024, 1024), interpolation=cv2.INTER_CUBIC)\n",
    "        mask = cv2.imread(mask_name)\n",
    "        mask = mask[:,:,0]\n",
    "        mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "        Xtrain.append(img)\n",
    "        Ytrain.append(mask)\n",
    "        if np.max(mask) >= 10:\n",
    "            print(np.max(mask), f' in image {mask_name} ')\n",
    "    return Xtrain, Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 163.50it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtest, Ytest = load_test_data(path='/mnt/data/med_data/balanced_batches/batch_3/test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = [i / 255 for i in Xtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from /home/rustam/EyePit/Danil_tests/Train_separate_NN_test/exp_2/7_class_only/exp_cv5_l2_v13/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=2/epoch_1/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/Xception_1024_testUnet_standart_V6_binary.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "prefix_path = '/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/'\n",
    "\n",
    "model.load_weights(prefix_path + 'exp_2/7_class_only/exp_cv5_l2_v13/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=2/epoch_1/' + 'weights.ckpt')\n",
    "\n",
    "answer_all = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()\n",
    "\n",
    "answer_7 = np.argmax(answer_all,axis=3) * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from /home/rustam/EyePit/Danil_tests/Train_separate_NN_test/exp_3/only_8_class/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=3/epoch_6/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/Xception_1024_testUnet_standart_V6_binary.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "prefix_path = '/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/'\n",
    "\n",
    "model.load_weights(prefix_path + 'exp_3/only_8_class/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=3/epoch_6/' +  'weights.ckpt')\n",
    "\n",
    "answer_all = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()\n",
    "\n",
    "answer_8 = np.argmax(answer_all,axis=3) * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from /home/rustam/EyePit/Danil_tests/Train_separate_NN_test/exp_4/only_6_class/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=6/epoch_2/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/Xception_1024_testUnet_standart_V6_binary.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "prefix_path = '/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/'\n",
    "\n",
    "model.load_weights(prefix_path + 'exp_4/only_6_class/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=6/epoch_2/'+ 'weights.ckpt')\n",
    "\n",
    "answer_all = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()\n",
    "\n",
    "answer_6 = np.argmax(answer_all,axis=3) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from /home/rustam/EyePit/Danil_tests/Train_separate_NN_test/exp_4/other_classes/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=8/epoch_12/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/exp_4/other_classes/Xception_1024_testUnet_standart_V6.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "prefix_path = '/home/rustam/EyePit/Danil_tests/Train_separate_NN_test/exp_4/other_classes/'\n",
    "\n",
    "model.load_weights(prefix_path + 'exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=8/epoch_12/' + 'weights.ckpt')\n",
    "\n",
    "answer_all = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()\n",
    "\n",
    "answer_others = np.argmax(answer_all,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(answer_others[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_oth = mutate_masks(answer_others,mapping=[(1,1),(2,2),(3,3),(4,4),(5,8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer_merged = []\n",
    "for i in range(len(Xtest)):\n",
    "    answer_merged.append(merging_masks([answer_oth[i],answer_7[i], answer_8[i], answer_6[i]],0,priority=[7,6,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.metrics.utils import one_hot\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_classes = [ str(i) for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_merged = np.asarray(answer_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_merged = answer_merged.reshape(-1)\n",
    "answer_merged = one_hot(answer_merged, depth=9)\n",
    "answer_merged = answer_merged.reshape(16, -1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest = np.asarray(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest = mutate_masks(Ytest,mapping=[(4,0),(5,4),(6,5),(7,6),(8,7),(9,8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-9\n",
    "\n",
    "\n",
    "def categorical_dice_coeff(P, L, use_argmax=False, ind_norm=True):\n",
    "    \"\"\"\n",
    "    Calculates V-Dice for give predictions and labels.\n",
    "    WARNING! THIS IMPLIES SEGMENTATION CONTEXT.\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : np.ndarray\n",
    "        Predictions of a segmentator. Array of shape [batch_sz, W, H, num_classes].\n",
    "    L : np.ndarray\n",
    "        Labels for the segmentator. Array of shape [batch_sz, W, H]\n",
    "    use_argmax : bool\n",
    "        Converts the segmentator's predictions to one-hot format.\n",
    "        Example: [0.4, 0.1, 0.5] -> [0., 0., 1.]\n",
    "    ind_norm : bool\n",
    "        Normalize each dice separately. Useful in case some classes don't appear\n",
    "        on some images.\n",
    "    \"\"\"\n",
    "    batch_sz = len(P)\n",
    "    L = np.asarray(L)\n",
    "    P = np.asarray(P)\n",
    "    num_classes = P.shape[-1]\n",
    "    if use_argmax:\n",
    "        P = P.argmax(axis=3)\n",
    "        P = P.reshape(-1)\n",
    "        P = one_hot(P, depth=num_classes)\n",
    "    P = P.reshape(batch_sz, -1, num_classes)\n",
    "    L = L.reshape(batch_sz, -1)\n",
    "\n",
    "    class_dices = np.zeros(num_classes)\n",
    "    class_counts = np.zeros(num_classes) + EPSILON  # Smoothing to avoid division by zero\n",
    "    for i in range(batch_sz):\n",
    "        sample_actual = L[i]\n",
    "        sample_pred = P[i]\n",
    "        for j in range(num_classes):\n",
    "            sub_actual = (sample_actual[:] == j).astype(np.int32)\n",
    "            sub_confs = sample_pred[:, j]\n",
    "            if np.sum(sub_actual) == 0 and np.sum(sub_confs) == 0:\n",
    "                continue\n",
    "            class_dices[j] += binary_dice(sub_confs, sub_actual)\n",
    "            class_counts[j] += 1\n",
    "\n",
    "    v_dice, dices = class_dices.mean() / batch_sz, class_dices / batch_sz\n",
    "    if ind_norm:\n",
    "        v_dice, dices = (class_dices / class_counts).mean(), class_dices / class_counts\n",
    "    return v_dice, dices\n",
    "\n",
    "\n",
    "def v_dice_coeff(P, L, use_argmax=False, one_hot_labels=False):\n",
    "    \"\"\"\n",
    "    Calculates V-Dice for give predictions and labels.\n",
    "    WARNING! THIS IMPLIES SEGMENTATION CONTEXT.\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : np.ndarray\n",
    "        Predictions of a segmentator. Array of shape [batch_sz, W, H, num_classes].\n",
    "    L : np.ndarray\n",
    "        Labels for the segmentator. Array of shape [batch_sz, W, H]\n",
    "    use_argmax : bool\n",
    "        Converts the segmentator's predictions to one-hot format.\n",
    "        Example: [0.4, 0.1, 0.5] -> [0., 0., 1.]\n",
    "    one_hot_labels : bool\n",
    "        Set to True if the labels (`L`) are already one-hot encoded, i.e. have the same\n",
    "        shape as `P`.\n",
    "    \"\"\"\n",
    "    # P has shape [batch_sz, W, H, num_classes]\n",
    "    # L has shape [batch_sz, W, H]\n",
    "    # RESHAPE TENSORS AND ONE-HOT LABELS\n",
    "    # P -> [batch_sz, num_samples, num_classes]\n",
    "    batch_sz = len(P)\n",
    "    num_samples = P.shape[1] * P.shape[2]\n",
    "    num_classes = P.shape[-1]\n",
    "    if use_argmax:\n",
    "        P = P.argmax(axis=3)\n",
    "        P = P.reshape(batch_sz * num_samples)\n",
    "        P = one_hot(P, depth=num_classes)\n",
    "    P = P.reshape(batch_sz, num_samples, num_classes)\n",
    "\n",
    "    if not one_hot_labels:\n",
    "        # L -> [batch_sz*num_samples] -> [batch_sz*num_samples, num_classes] -> [batch_sz, num_samples, num_classes]\n",
    "        L = L.reshape(batch_sz * num_samples)\n",
    "        L = one_hot(L, depth=num_classes)\n",
    "        L = L.reshape(batch_sz, num_samples, num_classes)\n",
    "\n",
    "    # P has shape [batch_sz, num_samples, num_classes]\n",
    "    # L has shape [batch_sz, num_samples, num_classes]\n",
    "    R = P * L\n",
    "    nums = R.sum(axis=1)\n",
    "\n",
    "    P2 = P * P\n",
    "    P2vec = P2.sum(axis=1)\n",
    "    Lvec = L.sum(axis=1)\n",
    "    dens = P2vec + Lvec\n",
    "    dices_b = (2 * nums + EPSILON) / (dens + EPSILON)\n",
    "    dices = dices_b.mean(axis=0)\n",
    "    return dices.mean(), dices\n",
    "\n",
    "\n",
    "def confusion_mat(\n",
    "        p, l,\n",
    "        use_argmax_p=False, use_argmax_l=False, to_flatten=False, normalize=[0, 1],\n",
    "        save_path=None, dpi=150, annot=True\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Creates confusion matrix for the given predictions `p` and labels `l`.\n",
    "    The matrix consists of elements C(i,j). C(i,j) - number of samples of class i\n",
    "    classified as class j.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : np.ndarray\n",
    "        Predictions.\n",
    "    l : np.ndarray\n",
    "        Corresponding labels.\n",
    "    use_argmax_p : bool\n",
    "        Set to true if prediction aren't sparse, i.e. `p` is an array of shape [..., num_classes].\n",
    "    use_argmax_l : bool\n",
    "        Set to True if labels aren't sparse (one-hot encoded), i.e. `l` is an array of shape [..., num_classes].\n",
    "    to_flatten : bool\n",
    "        Set to True if `p' and `l` are high-dimensional arrays.\n",
    "    normalize : list \n",
    "        List of axes. The matrix will be normalized along these axes.\n",
    "        Axis 1:\n",
    "            Normalizing by the number of true samples per class.\n",
    "            C(i,j) - percentage of samples of class i that classified as class j.\n",
    "            Diagonal elements stand for recall.\n",
    "        Axis 0:\n",
    "            Normalizing by the number of the network predictions per class.\n",
    "            C(i,j) - percentage of samples classified as j that actually belong to class i.\n",
    "            Diagonal elements stand for precision.\n",
    "        Leave the list empty if you want to get unnormalized matrix.\n",
    "    save_path : str\n",
    "        Saving path for the confusion matrix picture.\n",
    "    dpi : int\n",
    "        Affects the size of the saved confusion matrix picture.\n",
    "    annot : bool\n",
    "        Set to true if you want to see actual numbers (classes) on the matrix picture.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Confusion matrices.\n",
    "    \"\"\"\n",
    "    if use_argmax_p:\n",
    "        p = p.argmax(axis=-1)\n",
    "\n",
    "    if use_argmax_l:\n",
    "        l = l.argmax(axis=-1)\n",
    "\n",
    "    if to_flatten:\n",
    "        p = p.reshape(-1)\n",
    "        l = l.reshape(-1)\n",
    "\n",
    "    mat = np.asarray(confusion_matrix(l, p), dtype=np.float32)\n",
    "    del p\n",
    "    del l\n",
    "    \n",
    "    assert(len(normalize) < 3)\n",
    "    \n",
    "    if len(normalize) == 2:\n",
    "        \n",
    "        mats = []\n",
    "        for ax in normalize:\n",
    "            # Normalizing along axis 0\n",
    "            if ax == 0:\n",
    "                temp_mat = mat / mat.sum(axis=0)\n",
    "            # Normalizing along axis 1\n",
    "            elif ax == 1:\n",
    "                temp_mat = (mat.T / mat.sum(axis=1)).T\n",
    "            else:\n",
    "                raise RuntimeError(f\"Unknown axis: {ax}\")\n",
    "            temp_mat = np.round(temp_mat, decimals=2)\n",
    "            mats += [temp_mat]\n",
    "            \n",
    "        if save_path is not None:\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6.4))\n",
    "            sns.heatmap(mats[0], annot=annot, ax=axes[0])\n",
    "            axes[0].set_title(f'Axis {normalize[0]}')\n",
    "            sns.heatmap(mats[1], annot=annot, ax=axes[1])\n",
    "            axes[1].set_title(f'Axis {normalize[1]}')\n",
    "            fig.savefig(save_path)\n",
    "            plt.close(fig)\n",
    "        \n",
    "        return mats\n",
    "\n",
    "    if len(normalize) == 1:\n",
    "        ax = normalize[0]\n",
    "        # Normalizing along axis 0\n",
    "        if ax == 0:\n",
    "            mat = mat / mat.sum(axis=0)\n",
    "        # Normalizing along axis 1\n",
    "        elif ax == 1:\n",
    "            mat = (mat.T / mat.sum(axis=1)).T\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unknown axis: {ax}\")\n",
    "        mat = np.round(mat, decimals=2)\n",
    "\n",
    "    if save_path is not None:\n",
    "        conf_mat = sns.heatmap(mat, annot=annot)\n",
    "        conf_mat.figure.savefig(save_path, dpi=dpi)\n",
    "        plt.close(conf_mat.figure)\n",
    "\n",
    "    return [mat]\n",
    "\n",
    "\n",
    "def binary_dice(predicted, actual):\n",
    "    num = np.sum(predicted * actual)\n",
    "    den = np.sum(predicted * predicted) + np.sum(actual)\n",
    "    return (2 * num + EPSILON) / (den + EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Dice: 0.5202994572386749\n",
      "0: 0.9579113947899555\n",
      "1: 0.8794554997769812\n",
      "2: 0.681739886450964\n",
      "3: 0.7277670772843542\n",
      "4: 0.5502047641834295\n",
      "5: 0.1876329254669759\n",
      "6: 0.04087696833793567\n",
      "7: 0.030878885998157603\n",
      "8: 0.6262277128593211\n",
      "Computing confusion matrix...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.95, 0.04, 0.26, 0.23, 0.3 , 0.34, 0.62, 0.58, 0.24],\n",
       "        [0.  , 0.95, 0.  , 0.01, 0.  , 0.05, 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.72, 0.  , 0.04, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.03, 0.01, 0.  , 0.75, 0.01, 0.03, 0.01, 0.03, 0.02],\n",
       "        [0.  , 0.  , 0.01, 0.  , 0.62, 0.01, 0.08, 0.03, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.57, 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.27, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.34, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.74]],\n",
       "       dtype=float32),\n",
       " array([[0.97, 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.11, 0.86, 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.31, 0.  , 0.67, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.29, 0.  , 0.  , 0.7 , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.3 , 0.  , 0.03, 0.01, 0.65, 0.  , 0.02, 0.  , 0.  ],\n",
       "        [0.73, 0.  , 0.  , 0.01, 0.  , 0.25, 0.  , 0.  , 0.01],\n",
       "        [0.64, 0.  , 0.  , 0.  , 0.09, 0.  , 0.26, 0.  , 0.  ],\n",
       "        [0.79, 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.16, 0.01],\n",
       "        [0.41, 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.57]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPUTE DICE AND CREATE CONFUSION MATRIX\n",
    "v_dice_val, dices = categorical_dice_coeff(answer_merged, Ytest, use_argmax=False)\n",
    "\n",
    "print('V-Dice:', v_dice_val)\n",
    "for i, class_name in enumerate(name_classes):\n",
    "    print(f'{class_name}:', dices[i])\n",
    "\n",
    "# Compute and save matrix\n",
    "conf_mat_path = f'mat_epoch.png'\n",
    "print('Computing confusion matrix...')\n",
    "confusion_mat(\n",
    "    answer_merged, Ytest, use_argmax_p=True, to_flatten=True,\n",
    "    save_path=conf_mat_path, dpi=175\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = copy.deepcopy(answer_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.reshape(-1)\n",
    "test = one_hot(test, depth=10)\n",
    "test = test.reshape(16, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Dice: 0.48050322294056286\n",
      "0: 0.9563937567568369\n",
      "1: 0.8662955174956187\n",
      "2: 0.6821455532621923\n",
      "3: 0.7224625801151546\n",
      "4: 5.416421907765949e-13\n",
      "5: 0.5312853465411852\n",
      "6: 0.3106011384624071\n",
      "7: 0.052382682113361716\n",
      "8: 0.06867535819430415\n",
      "9: 0.6147902964640262\n",
      "Computing confusion matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:167: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.95, 0.11, 0.25, 0.23,  nan, 0.41, 0.25, 0.3 , 0.59, 0.3 ],\n",
       "        [0.  , 0.85, 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.74, 0.  ,  nan, 0.05, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.03, 0.03, 0.  , 0.76,  nan, 0.01, 0.01, 0.  , 0.01, 0.02],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.49, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.74, 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.03, 0.  , 0.69, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.01, 0.39, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.67]],\n",
       "       dtype=float32),\n",
       " array([[0.96, 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.06, 0.93, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.31, 0.  , 0.65, 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.3 , 0.01, 0.  , 0.69, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.94, 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.02],\n",
       "        [0.26, 0.  , 0.  , 0.01, 0.  , 0.73, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.72, 0.  , 0.01, 0.  , 0.  , 0.  , 0.26, 0.  , 0.  , 0.01],\n",
       "        [0.72, 0.  , 0.  , 0.01, 0.  , 0.21, 0.  , 0.07, 0.  , 0.  ],\n",
       "        [0.79, 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.  , 0.15, 0.02],\n",
       "        [0.37, 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.6 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPUTE DICE AND CREATE CONFUSION MATRIX\n",
    "v_dice_val, dices = categorical_dice_coeff(test, Ytest, use_argmax=False)\n",
    "\n",
    "print('V-Dice:', v_dice_val)\n",
    "for i, class_name in enumerate(name_classes):\n",
    "    print(f'{class_name}:', dices[i])\n",
    "\n",
    "# Compute and save matrix\n",
    "conf_mat_path = f'mat_epoch.png'\n",
    "print('Computing confusion matrix...')\n",
    "confusion_mat(\n",
    "    test, Ytest, use_argmax_p=True, to_flatten=True,\n",
    "    save_path=conf_mat_path, dpi=175\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = np.asarray(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = test_2.reshape(-1)\n",
    "test_2 = one_hot(test_2, depth=10)\n",
    "test_2 = test_2.reshape(16, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V-Dice: 0.48050322294056286\n",
      "0: 0.9563937567568369\n",
      "1: 0.8662955174956187\n",
      "2: 0.6821455532621923\n",
      "3: 0.7224625801151546\n",
      "4: 5.416421907765949e-13\n",
      "5: 0.5312853465411852\n",
      "6: 0.3106011384624071\n",
      "7: 0.052382682113361716\n",
      "8: 0.06867535819430415\n",
      "9: 0.6147902964640262\n",
      "Computing confusion matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustam/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:167: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.95, 0.11, 0.25, 0.23,  nan, 0.41, 0.25, 0.3 , 0.59, 0.3 ],\n",
       "        [0.  , 0.85, 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.74, 0.  ,  nan, 0.05, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.03, 0.03, 0.  , 0.76,  nan, 0.01, 0.01, 0.  , 0.01, 0.02],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.49, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.74, 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.03, 0.  , 0.69, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.01, 0.39, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.67]],\n",
       "       dtype=float32),\n",
       " array([[0.96, 0.  , 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.06, 0.93, 0.  , 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.31, 0.  , 0.65, 0.  , 0.  , 0.04, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.3 , 0.01, 0.  , 0.69, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.94, 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.02],\n",
       "        [0.26, 0.  , 0.  , 0.01, 0.  , 0.73, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.72, 0.  , 0.01, 0.  , 0.  , 0.  , 0.26, 0.  , 0.  , 0.01],\n",
       "        [0.72, 0.  , 0.  , 0.01, 0.  , 0.21, 0.  , 0.07, 0.  , 0.  ],\n",
       "        [0.79, 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.  , 0.15, 0.02],\n",
       "        [0.37, 0.  , 0.  , 0.03, 0.  , 0.  , 0.  , 0.  , 0.  , 0.6 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPUTE DICE AND CREATE CONFUSION MATRIX\n",
    "v_dice_val, dices = categorical_dice_coeff(test_2, Ytest, use_argmax=False)\n",
    "\n",
    "print('V-Dice:', v_dice_val)\n",
    "for i, class_name in enumerate(name_classes):\n",
    "    print(f'{class_name}:', dices[i])\n",
    "\n",
    "# Compute and save matrix\n",
    "conf_mat_path = f'mat_epoch.png'\n",
    "print('Computing confusion matrix...')\n",
    "confusion_mat(\n",
    "    test_2, Ytest, use_argmax_p=True, to_flatten=True,\n",
    "    save_path=conf_mat_path, dpi=175\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

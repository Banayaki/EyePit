{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from makiflow.layers import *\n",
    "from makiflow.models.segmentation.segmentator import Segmentator\n",
    "from makiflow.tf_scripts import set_main_gpu\n",
    "set_main_gpu(1)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from makiflow.models.classificator import Classificator\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def merging_masks(masks, index_of_main_mask, priority):\n",
    "    \"\"\"\n",
    "    We choose the base mask which have index `index_of_main_mask` on which is put other classes\n",
    "    according to `priority` of other classes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    masks : list or numpy.array\n",
    "        List or numpy array of masks.\n",
    "    index_of_main_mask : int\n",
    "        Index of base mask.\n",
    "    priority : list\n",
    "        List of priority of classes. From highest priority to least priority.\n",
    "        Example: [9, 10, 3, 7], where 9 class have highest priority and will be put on others classes,\n",
    "        on the other hand the 7th class have the lowest priority and will be put on the others the latest.\n",
    "    Returns\n",
    "    ---------\n",
    "    main_mask : numpy.array\n",
    "        The base mask after merging other classes.\n",
    "    \"\"\"\n",
    "\n",
    "    # For easy access\n",
    "    main_mask = masks[index_of_main_mask]\n",
    "\n",
    "    # Thanks to the `boolean_mask` higher priority class will not be erased\n",
    "    boolean_mask = np.ones(main_mask.shape).astype(np.bool)\n",
    "\n",
    "    for i in range(len(masks)):\n",
    "        if i == index_of_main_mask:\n",
    "            continue\n",
    "\n",
    "        for prior in priority:\n",
    "            main_mask[masks[i] == prior * boolean_mask] = prior\n",
    "            boolean_mask[masks[i] == prior] = False\n",
    "\n",
    "    return main_mask\n",
    "\n",
    "\n",
    "def mutate_masks(masks, mapping):\n",
    "    \"\"\"\n",
    "    Remaps classes on the given `masks` according to the `mapping`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    masks : list or numpy.array\n",
    "        List or numpy array of masks.\n",
    "    mapping : list\n",
    "        List of tuples: [(source_class_number, new_class_number)],\n",
    "        where `source_class_number` will be changed to `new_class_number` in the `masks`.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    new_masks : the same type as `masks`\n",
    "        New masks with changed class numbers.\n",
    "    \"\"\"\n",
    "    if type(mapping) is not list or (len(mapping) != 0 and type(mapping[0]) is not tuple):\n",
    "        raise TypeError('mapping should be list of typles')\n",
    "\n",
    "    new_masks = copy.deepcopy(masks)\n",
    "\n",
    "    for i in range(len(new_masks)):\n",
    "        for elem in mapping:\n",
    "            old_value = elem[0]\n",
    "            new_value = elem[1]\n",
    "            new_masks[i][masks[i] == old_value] = new_value\n",
    "\n",
    "    return  new_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.save_recover import Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    Xtrain, Ytrain = [], []\n",
    "    masks = glob.glob(path + '/masks/*.bmp')\n",
    "    masks.sort()\n",
    "    for mask_name in tqdm(masks):\n",
    "        img = cv2.imread(mask_name.replace('masks', 'images'))\n",
    "        img = cv2.resize(img, (1024, 1024), interpolation=cv2.INTER_CUBIC)\n",
    "        mask = cv2.imread(mask_name)\n",
    "        mask = mask[:,:,0]\n",
    "        mask = cv2.resize(mask, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "        Xtrain.append(img)\n",
    "        Ytrain.append(mask)\n",
    "        if np.max(mask) >= 10:\n",
    "            print(np.max(mask), f' in image {mask_name} ')\n",
    "    return Xtrain, Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 116.37it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtest, Ytest = load_test_data(path='/mnt/data/med_data/balanced_batches/batch_3/test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = [i / 255 for i in Xtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from other_classes/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=8/epoch_15/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('other_classes/Xception_1024_testUnet_standart_V6.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "model.load_weights('other_classes/exp_cv3/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=8/epoch_15/weights.ckpt')\n",
    "\n",
    "answer_all = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()\n",
    "\n",
    "answer_all = np.argmax(answer_all,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_all = mutate_masks(answer_all,mapping=[(4,5),(5,6),(6,8),(7,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from ../exp_1/4_class_only/exp_cv3/x-65/MakiSegmentator_gamma=6_opt_name=adam1_bsz=6/epoch_7/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('../exp_1/4_class_only/Xception_1024_testUnet_standart_V6.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "model.load_weights('../exp_1/4_class_only/exp_cv3/x-65/MakiSegmentator_gamma=6_opt_name=adam1_bsz=6/epoch_7/weights.ckpt')\n",
    "\n",
    "answer_4 = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_4 = np.argmax(answer_4, axis=3) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n",
      "INFO:tensorflow:Restoring parameters from 7_class_only/exp_cv5_l2_v13/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=2/epoch_1/weights.ckpt\n",
      "Weights are loaded.\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json('7_class_only/Xception_1024_testUnet_standart_V6.json', batch_size=16)\n",
    "\n",
    "ses = tf.Session()\n",
    "model.set_session(ses)\n",
    "\n",
    "model.load_weights('7_class_only/exp_cv5_l2_v13/x-65/MakiSegmentator_gamma=2_opt_name=adam1_bsz=2/epoch_1/weights.ckpt')\n",
    "\n",
    "answer_7 = ses.run(tf.nn.softmax(model.predict(Xtest)))\n",
    "\n",
    "ses.close()\n",
    "\n",
    "answer_7 = np.argmax(answer_7,axis=3) * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_merged = []\n",
    "for i in range(len(Xtest)):\n",
    "    answer_merged.append(merging_masks([answer_all[i],answer_4[i],answer_7[i]],0,priority=[4,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.metrics import categorical_dice_coeff, confusion_mat\n",
    "from makiflow.metrics.utils import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_classes = [ str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_merged = np.asarray(answer_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_merged = answer_merged.reshape(-1)\n",
    "answer_merged = one_hot(answer_merged, depth=10)\n",
    "answer_merged = answer_merged.reshape(16, -1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest = np.asarray(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-9\n",
    "\n",
    "def categorical_dice_coeff(P, L, use_argmax=False, ind_norm=True):\n",
    "    \"\"\"\n",
    "    Calculates V-Dice for give predictions and labels.\n",
    "    WARNING! THIS IMPLIES SEGMENTATION CONTEXT.\n",
    "    Parameters\n",
    "    ----------\n",
    "    P : np.ndarray\n",
    "        Predictions of a segmentator. Array of shape [batch_sz, W, H, num_classes].\n",
    "    L : np.ndarray\n",
    "        Labels for the segmentator. Array of shape [batch_sz, W, H]\n",
    "    use_argmax : bool\n",
    "        Converts the segmentator's predictions to one-hot format.\n",
    "        Example: [0.4, 0.1, 0.5] -> [0., 0., 1.]\n",
    "    ind_norm : bool\n",
    "        Normalize each dice separately. Useful in case some classes don't appear\n",
    "        on some images.\n",
    "    \"\"\"\n",
    "    batch_sz = len(P)\n",
    "    print(batch_sz)\n",
    "    L = np.asarray(L)\n",
    "    P = np.asarray(P)\n",
    "    num_classes = P.shape[-1]\n",
    "    if use_argmax:\n",
    "        P = P.argmax(axis=3)\n",
    "        P = P.reshape(-1)\n",
    "        P = one_hot(P, depth=num_classes)\n",
    "    P = P.reshape(batch_sz, -1, num_classes)\n",
    "    L = L.reshape(batch_sz, -1)\n",
    "\n",
    "    class_dices = np.zeros(num_classes)\n",
    "    class_counts = np.zeros(num_classes) + EPSILON  # Smoothing to avoid division by zero\n",
    "    for i in range(batch_sz):\n",
    "        sample_actual = L[i]\n",
    "        sample_pred = P[i]\n",
    "        for j in range(num_classes):\n",
    "            sub_actual = (sample_actual[:] == j).astype(np.int32)\n",
    "            sub_confs = sample_pred[:, j]\n",
    "            if np.sum(sub_actual) == 0 and np.sum(sub_confs) == 0:\n",
    "                continue\n",
    "            class_dices[j] += binary_dice(sub_confs, sub_actual)\n",
    "            class_counts[j] += 1\n",
    "\n",
    "    v_dice, dices = class_dices.mean() / batch_sz, class_dices / batch_sz\n",
    "    if ind_norm:\n",
    "        v_dice, dices = (class_dices / class_counts).mean(), class_dices / class_counts\n",
    "    return v_dice, dices\n",
    "\n",
    "def binary_dice(predicted, actual):\n",
    "    num = np.sum(predicted * actual)\n",
    "    den = np.sum(predicted * predicted) + np.sum(actual)\n",
    "    return (2 * num + EPSILON) / (den + EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "V-Dice: 0.4689225858189707\n",
      "0: 0.9560223898641762\n",
      "1: 0.8452420646770852\n",
      "2: 0.6679100722046011\n",
      "3: 0.7287975416341761\n",
      "4: 5.416421907765949e-13\n",
      "5: 0.5555328724166723\n",
      "6: 0.16403218445409734\n",
      "7: 0.04081695362405828\n",
      "8: 0.10132218148265787\n",
      "9: 0.6295495978316412\n",
      "Computing confusion matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustam/anaconda3/lib/python3.6/site-packages/makiflow/metrics/metrics.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
      "  temp_mat = mat / mat.sum(axis=ax)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.95, 0.07, 0.27, 0.26,  nan, 0.28, 0.29, 0.62, 0.46, 0.27],\n",
       "        [0.  , 0.91, 0.  , 0.01,  nan, 0.  , 0.  , 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.72, 0.  ,  nan, 0.07, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.03, 0.02, 0.  , 0.73,  nan, 0.01, 0.  , 0.01, 0.02, 0.02],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.63, 0.01, 0.08, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.69, 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.01, 0.  , 0.27, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.01, 0.52, 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  ,  nan, 0.  , 0.  , 0.  , 0.  , 0.7 ]],\n",
       "       dtype=float32),\n",
       " array([[0.96, 0.07, 0.24, 0.26, 0.  , 0.3 , 0.06, 0.61, 0.09, 0.23],\n",
       "        [0.  , 0.86, 0.  , 0.01, 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.65, 0.  , 0.  , 0.07, 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.03, 0.02, 0.  , 0.73, 0.  , 0.01, 0.  , 0.01, 0.  , 0.02],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.68, 0.  , 0.08, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.01, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.26, 0.  , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.1 , 0.  ],\n",
       "        [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.61]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPUTE DICE AND CREATE CONFUSION MATRIX\n",
    "v_dice_val, dices = categorical_dice_coeff(answer_merged, Ytest, use_argmax=False)\n",
    "\n",
    "print('V-Dice:', v_dice_val)\n",
    "for i, class_name in enumerate(name_classes):\n",
    "    print(f'{class_name}:', dices[i])\n",
    "\n",
    "# Compute and save matrix\n",
    "conf_mat_path = f'mat_epoch.png'\n",
    "print('Computing confusion matrix...')\n",
    "confusion_mat(\n",
    "    answer_merged, Ytest, use_argmax_p=True, to_flatten=True,\n",
    "    save_path=conf_mat_path, dpi=175\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

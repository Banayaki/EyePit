{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/rustam/EyePit/Danil_tests/MakiFlow/')\n",
    "from makiflow.models import Segmentator\n",
    "from makiflow.layers import *\n",
    "import makiflow as mf\n",
    "import tensorflow as tf\n",
    "mf.set_main_gpu(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to provide a path provider to our data that will tell the generator where to load the data from.\n",
    "For this purpose we're gonna create a generator that is gonna yield strings with path to the necessary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.models.segmentation.gen_base import PathGenerator, SegmentIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path provider must inherited from the <b>PathGenerator</b> class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/mnt/data/med_data/balanced_batches/bb_danil1/images'\n",
    "masks_path = '/mnt/data/med_data/balanced_batches/bb_danil1/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Generator(PathGenerator):\n",
    "    def __init__(self, path_imgs, path_masks):\n",
    "        self.images = glob(os.path.join(path_imgs, '*.bmp'))\n",
    "        self.masks = glob(os.path.join(path_masks, '*.bmp'))\n",
    "        \n",
    "    def next_element(self):\n",
    "        while True:\n",
    "            index = np.random.randint(low=0, high=len(self.images))\n",
    "            \n",
    "            yield {\n",
    "                SegmentIterator.image: self.images[index],\n",
    "                SegmentIterator.mask: self.masks[index]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a map method that will map from the path string to the actual data, i.e. it's a function that loads the data according the given paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example map method\n",
    "def ex_map_method(data_paths):\n",
    "    img_file = tf.read_file(data_paths[SegmentationGenerator.image])\n",
    "    mask_file = tf.read_file(data_paths[SegmentationGenerator.mask])\n",
    "\n",
    "    img = tf.image.decode_image(img_file)\n",
    "    mask = tf.image.decode_image(mask_file)\n",
    "\n",
    "    img.set_shape([1024, 1024, 3])\n",
    "    mask.set_shape([1024, 1024, 3])\n",
    "    \n",
    "    # The mask has three channels so we need to squeeze it\n",
    "    mask = mask[:, :, 0]\n",
    "    \n",
    "    img = tf.cast(img, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.int32)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MakiFlow provides already built map methods.\n",
    "<b><ol>\n",
    "    <li>LoadResizeNormalize - shortcut method</li>\n",
    "    <li>LoadDataMethod - constructive method (the beginning block)</li>\n",
    "    <li>ResizePostMethod - constructive method</li>\n",
    "    <li>NormalizePostMethod - constructive method</li>\n",
    "    <li>SqueezeMaskPostMethod - constructive method</li>\n",
    "    <li>ComputePositivesPostMethod - constructive method</li>\n",
    "</ol></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a map method by combining the aforementioned ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.models.segmentation.map_methods import LoadDataMethod, ResizePostMethod, ComputePositivesPostMethod, \\\n",
    "    SqueezeMaskPostMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_method = LoadDataMethod(image_shape=[1024, 1024, 3], mask_shape=[1024, 1024, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_method = SqueezeMaskPostMethod()(map_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_method = ComputePositivesPostMethod(dtype=tf.int32)(map_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After acquiring map method and path provider we can create the generator layer. This layer will feed the network with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.models.segmentation.gen_layers import InputGenLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_layer = InputGenLayer(\n",
    "    prefetch_size=5,\n",
    "    batch_size=1, \n",
    "    path_generator=Generator(images_path, masks_path),\n",
    "    name='1',\n",
    "    map_operation=map_method\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model from generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model can be built using classic approach - layer by layer - or with the help of the builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.save_recover import Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is restored!\n"
     ]
    }
   ],
   "source": [
    "model = Builder.segmentator_from_json(\n",
    "    json_path='/home/rustam/EyePit/Models/x65/xception_unet_v12_with_atrous.json',\n",
    "    generator=gen_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can trained now using familiar, but a little bit different API.\n",
    "At first we need to tell the model (Segmentator) that it's gonna be trained using generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generator(gen_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_session(tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <tf.Tensor 'IteratorGetNext:0' shape=(1, 1024, 1024, 3) dtype=float32>,\n",
       " 'mask': <tf.Tensor 'IteratorGetNext:1' shape=(1, 1024, 1024) dtype=int32>,\n",
       " 'num_positives': <tf.Tensor 'IteratorGetNext:2' shape=(1,) dtype=float32>}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._generator.get_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set an optimizer and the number of epochs as usual. But in case of training using pipelines there's no common sense for epochs, so we need to define ourselves how long the epoch is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "iterations = 10 # How many batches are processed during one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.genfit_focal(\n",
    "    gamma=2.0,\n",
    "    optimizer=optimizer,\n",
    "    epochs=10,\n",
    "    iterations=iterations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "\n",
    "from makiflow.augmentation import AffineAugment, ElasticAugment, ImageCutter, Data\n",
    "from makiflow.augmentation.segmentation import HCScanner\n",
    "from makiflow.augmentation.segmentation import GDBalancer\n",
    "from makiflow.augmentation.segmentation.balancing.utils import hcv_to_num\n",
    "from makiflow.augmentation.segmentation import GD2BBuilder\n",
    "from makiflow.tf_scripts import set_main_gpu\n",
    "set_main_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_masks(masks, mapping):\n",
    "    \"\"\"\n",
    "    Remaps classes on the given `masks` according to the `mapping`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    masks : list or numpy.array\n",
    "        List or numpy array of masks.\n",
    "    mapping : list\n",
    "        List of tuples: [(source_class_number, new_class_number)],\n",
    "        where `source_class_number` will be changed to `new_class_number` in the `masks`.\n",
    "    Returns\n",
    "    ---------\n",
    "    new_masks : the same type as `masks`\n",
    "        New masks with changed class numbers.\n",
    "    \"\"\"\n",
    "    if type(mapping) is not list or (len(mapping) != 0 and type(mapping[0]) is not tuple):\n",
    "        raise TypeError('mapping should be list of typles')\n",
    "\n",
    "    new_masks = copy.deepcopy(masks)\n",
    "\n",
    "    for i in range(len(new_masks)):\n",
    "        for elem in mapping:\n",
    "            old_value = elem[0]\n",
    "            new_value = elem[1]\n",
    "            new_masks[i][masks[i] == old_value] = new_value\n",
    "\n",
    "    return  new_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_main_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_names = glob(f'/mnt/data/med_data/balanced_batches/batch_{batch_num}/train_set/origin_wo_4_set/masks/*.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE) for mask_name in mask_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {mask_name: mask for mask_name, mask in zip(mask_names, masks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner = HCScanner(masks, 9)\n",
    "scanner.scan()\n",
    "scanner.save_info(f'uniq_hvc_{batch_num}.csv', f'masks_hcvg_{batch_num}.csv')\n",
    "len(scanner.hcv_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>hcvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/data/med_data/balanced_batches/batch_3/tr...</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/data/med_data/balanced_batches/batch_3/tr...</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/data/med_data/balanced_batches/batch_3/tr...</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/data/med_data/balanced_batches/batch_3/tr...</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/data/med_data/balanced_batches/batch_3/tr...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  hcvg\n",
       "0  /mnt/data/med_data/balanced_batches/batch_3/tr...   319\n",
       "1  /mnt/data/med_data/balanced_batches/batch_3/tr...   319\n",
       "2  /mnt/data/med_data/balanced_batches/batch_3/tr...   447\n",
       "3  /mnt/data/med_data/balanced_batches/batch_3/tr...   319\n",
       "4  /mnt/data/med_data/balanced_batches/batch_3/tr...   271"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_hcvg = pd.read_csv(f'masks_hcvg_{batch_num}.csv', index_col=False)\n",
    "masks_hcvg.columns = ['path', 'hcvg']\n",
    "masks_hcvg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to image: /mnt/data/med_data/balanced_batches/batch_3/train_set/origin_wo_4_set/masks/0.bmp, hcvg: 319\n"
     ]
    }
   ],
   "source": [
    "for index, row in masks_hcvg.iterrows():\n",
    "    print(f\"Path to image: {row['path']}, hcvg: {row['hcvg']}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hcvg</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hcvg  0  1  2  3  4  5  6  7  8\n",
       "0   319  1  1  1  1  1  1  0  0  1\n",
       "1   447  1  1  1  1  1  1  0  1  1\n",
       "2   271  1  1  1  1  0  0  0  0  1\n",
       "3   303  1  1  1  1  0  1  0  0  1\n",
       "4   287  1  1  1  1  1  0  0  0  1"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_hvc = pd.read_csv(f'uniq_hvc_{batch_num}.csv', index_col=False)\n",
    "# Be carefull, here is unpacking\n",
    "uniq_hvc.columns = list(['hcvg', *uniq_hvc.columns[1:]])\n",
    "uniq_hvc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       " array([1, 1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 0, 0, 0, 1]),\n",
       " array([1, 1, 1, 1, 0, 1, 0, 0, 1]),\n",
       " array([1, 1, 0, 1, 1, 1, 0, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 0, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 0, 1, 0, 1]),\n",
       " array([1, 1, 0, 1, 1, 1, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 0, 1]),\n",
       " array([1, 1, 1, 1, 1, 0, 0, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 1, 0, 1, 1]),\n",
       " array([1, 1, 1, 1, 1, 0, 1, 1, 1])]"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_num = uniq_hvc.get_values()\n",
    "uniq_num = sorted(uniq_num, key=lambda x: x[0]) \n",
    "hcv_groups = [vec[1:] for vec in uniq_num]\n",
    "# hcv_groups = np.delete(hcv_groups, 4, axis=1)\n",
    "hcv_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete 4 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDBalancer Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(15, 3),\n",
       "             (31, 1),\n",
       "             (271, 5),\n",
       "             (287, 45),\n",
       "             (303, 1),\n",
       "             (315, 2),\n",
       "             (319, 28),\n",
       "             (351, 3),\n",
       "             (379, 1),\n",
       "             (383, 1),\n",
       "             (415, 5),\n",
       "             (447, 3),\n",
       "             (479, 1)])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weights = collections.OrderedDict(sorted(scanner.hcv_groups.items()))\n",
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = np.array(list(initial_weights.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  1,  5, 45,  1,  2, 28,  3,  1,  1,  5,  3,  1])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03],\n",
       "       [0.01],\n",
       "       [0.05],\n",
       "       [0.45],\n",
       "       [0.01],\n",
       "       [0.02],\n",
       "       [0.28],\n",
       "       [0.03],\n",
       "       [0.01],\n",
       "       [0.01],\n",
       "       [0.05],\n",
       "       [0.03],\n",
       "       [0.01]])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial cardinality distribution\n",
    "np.round(initial_weights / initial_weights.sum(), 2).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_w = np.array([80, 40, 70, 290, 40, 50, 250, 70, 40, 50, 100, 40, 50]) * 2 # 1 batch\n",
    "\n",
    "init_w = np.array([10] * 3 + [300] + [40] *2 + [160] + [10]*6)\n",
    "#init_w = np.array([20] * 13)\n",
    "# init_w = np.array([98, 98, 95, 60, 90, 98, 96, 70, 94, 94, 98, 96, 98, 98, 98])\n",
    "#init_w = np.array([60, 60, 63, 98, 68, 60, 62, 87, 64, 64, 60, 66, 60]) # The best. i think\n",
    "# init_w = np.array([100, 100, 103, 138, 108, 100, 102, 127, 104, 104, 100, 106, 100, 100, 100])\n",
    "# init_w = np.array([138, 138, 135, 100, 130, 138, 137, 110, 134, 134, 138, 132, 138, 138, 138])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_w = np.array([80, 40, 70, 290, 40, 50, 250, 70, 40, 50, 100, 40, 50]) * 2 \n",
    "# init_w = np.array([60, 60, 63, 98, 68, 60, 62, 87, 64, 64, 60, 66, 60])\n",
    "dest_v = np.array([0.99, 0.99, 0.99, 0.99, 0.99, 0.4, 0.2, 0.2, 0.99])\n",
    "\n",
    "balancer = GDBalancer(\n",
    "    hcv_groups=np.array(hcv_groups), \n",
    "    initial_c=init_w,\n",
    "    objective='alpha', min_c=20, max_c=2000) # 'uniq_hvc.csv'\n",
    "optimizer = tf.train.AdamOptimizer(1)\n",
    "\n",
    "balancer.add_reg2(0.000001, initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "balancer.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.],\n",
       "       [100.],\n",
       "       [ 92.],\n",
       "       [100.],\n",
       "       [ 90.],\n",
       "       [ 43.],\n",
       "       [  6.],\n",
       "       [  5.],\n",
       "       [ 97.]], dtype=float32)"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancer.get_percentage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08150501\n",
      "[[100.]\n",
      " [100.]\n",
      " [ 95.]\n",
      " [100.]\n",
      " [ 93.]\n",
      " [ 41.]\n",
      " [ 20.]\n",
      " [ 20.]\n",
      " [ 95.]]\n",
      "0.08062024\n",
      "[[100.]\n",
      " [100.]\n",
      " [ 95.]\n",
      " [100.]\n",
      " [ 93.]\n",
      " [ 41.]\n",
      " [ 21.]\n",
      " [ 20.]\n",
      " [ 95.]]\n"
     ]
    }
   ],
   "source": [
    "iterations = 3\n",
    "balancer.optimize(dest_v, optimizer, iterations=iterations, print_period=iterations - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1,   3],\n",
       "       [  1,   1],\n",
       "       [ -3,   5],\n",
       "       [-11,  45],\n",
       "       [  1,   1],\n",
       "       [  0,   2],\n",
       "       [ -8,  28],\n",
       "       [  3,   3],\n",
       "       [  1,   1],\n",
       "       [  5,   1],\n",
       "       [  2,   5],\n",
       "       [  4,   3],\n",
       "       [  5,   1]], dtype=int32)"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial cardinality distribution\n",
    "np.concatenate([np.round(balancer.show_deviation() * -1, 0) ,\n",
    "                np.round(initial_weights / initial_weights.sum(), 2).reshape(-1, 1)*100], axis=1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20.     ],\n",
       "       [ 20.     ],\n",
       "       [ 20.     ],\n",
       "       [296.28857],\n",
       "       [ 20.     ],\n",
       "       [ 20.     ],\n",
       "       [179.83429],\n",
       "       [ 49.86645],\n",
       "       [ 20.     ],\n",
       "       [ 54.32784],\n",
       "       [ 57.8166 ],\n",
       "       [ 59.72967],\n",
       "       [ 54.6839 ]], dtype=float32)"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100.],\n",
       "       [100.],\n",
       "       [ 95.],\n",
       "       [100.],\n",
       "       [ 93.],\n",
       "       [ 41.],\n",
       "       [ 21.],\n",
       "       [ 20.],\n",
       "       [ 95.]], dtype=float32)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancer.get_percentage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872.5473"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancer.get_weights().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare values to GD2BBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 20,  20,  20, 296,  20,  20, 180,  50,  20,  54,  58,  60,  55],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balancer_weights = balancer.get_weights()\n",
    "balancer_weights = balancer_weights.flatten().round().astype(np.int32)\n",
    "balancer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "for i in range(len(balancer_weights)):\n",
    "    config[hcv_to_num(balancer.hcv_groups[i])] = balancer_weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15: 20,\n",
       " 31: 20,\n",
       " 271: 20,\n",
       " 287: 296,\n",
       " 303: 20,\n",
       " 315: 20,\n",
       " 319: 180,\n",
       " 351: 50,\n",
       " 379: 20,\n",
       " 383: 54,\n",
       " 415: 58,\n",
       " 447: 60,\n",
       " 479: 55}"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "balancer.save_cardinalities(f'balancer_cardinalities_{batch_num}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GD2BBuilder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_names = glob(f'/mnt/data/med_data/balanced_batches/batch_{batch_num}/train_set/origin_wo_4_set/masks/*.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2image = {}\n",
    "for mask_name in lbl_names:\n",
    "    mask2image[mask_name] = mask_name.replace('masks', 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(mask2image, orient='index', columns=['image']).to_csv(f'mi_{batch_num}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rustam/anaconda3/lib/python3.6/site-packages/makiflow/augmentation/segmentation/balancing/gdbb_builder.py:24: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  self._hc_list = pd.DataFrame.from_csv(path_to_hc_list)\n",
      "/home/rustam/anaconda3/lib/python3.6/site-packages/makiflow/augmentation/segmentation/balancing/gdbb_builder.py:25: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  self._balance_c = pd.DataFrame.from_csv(path_to_balance_config)\n",
      "/home/rustam/anaconda3/lib/python3.6/site-packages/makiflow/augmentation/segmentation/balancing/gdbb_builder.py:34: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  mi = pd.DataFrame.from_csv(path_to_mi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading masks and images.\n",
      "Finished.\n",
      "Group masks and images by their ids.\n",
      "319 cardinality is 28\n",
      "447 cardinality is 3\n",
      "271 cardinality is 5\n",
      "303 cardinality is 1\n",
      "287 cardinality is 45\n",
      "351 cardinality is 3\n",
      "415 cardinality is 5\n",
      "315 cardinality is 2\n",
      "15 cardinality is 3\n",
      "379 cardinality is 1\n",
      "479 cardinality is 1\n",
      "31 cardinality is 1\n",
      "383 cardinality is 1\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "builder = GD2BBuilder(\n",
    "    path_to_balance_config=f'balancer_cardinalities_{batch_num}.csv',\n",
    "    path_to_hc_list=f'masks_hcvg_{batch_num}.csv',\n",
    "    path_to_mi=f'mi_{batch_num}.csv',\n",
    "    resize=(1024, 1024)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_elastic_aug_params((1024, 1024, 3), 700, 11, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing group 319...\n",
      "Augmentor updated 6 times.\n",
      "Finished.\n",
      "319 ready\n",
      "Balancing group 447...\n",
      "Augmentor updated 20 times.\n",
      "Finished.\n",
      "447 ready\n",
      "Balancing group 271...\n",
      "Augmentor updated 4 times.\n",
      "Finished.\n",
      "271 ready\n",
      "Balancing group 303...\n",
      "Augmentor updated 20 times.\n",
      "Finished.\n",
      "303 ready\n",
      "Balancing group 287...\n",
      "Augmentor updated 6 times.\n",
      "Finished.\n",
      "287 ready\n",
      "Balancing group 351...\n",
      "Augmentor updated 16 times.\n",
      "Finished.\n",
      "351 ready\n",
      "Balancing group 415...\n",
      "Augmentor updated 11 times.\n",
      "Finished.\n",
      "415 ready\n",
      "Balancing group 315...\n",
      "Augmentor updated 10 times.\n",
      "Finished.\n",
      "315 ready\n",
      "Balancing group 15...\n",
      "Augmentor updated 6 times.\n",
      "Finished.\n",
      "15 ready\n",
      "Balancing group 379...\n",
      "Augmentor updated 20 times.\n",
      "Finished.\n",
      "379 ready\n",
      "Balancing group 479...\n",
      "Augmentor updated 55 times.\n",
      "Finished.\n",
      "479 ready\n",
      "Balancing group 31...\n",
      "Augmentor updated 20 times.\n",
      "Finished.\n",
      "31 ready\n",
      "Balancing group 383...\n",
      "Augmentor updated 54 times.\n",
      "Finished.\n",
      "383 ready\n"
     ]
    }
   ],
   "source": [
    "builder.create_batch(f'/mnt/data/med_data/balanced_batches/batch_{batch_num}/train_set/aug_set/set_1024_10k_wo_4_4/origin_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = glob(f'/mnt/data/med_data/balanced_batches/batch_{batch_num}/train_set/aug_set/set_1024_wo_elastic_paper_test#3_3/masks/*.bmp')\n",
    "lbls = []\n",
    "for mask_name in test:\n",
    "    lbls += [cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)]\n",
    "len(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(lbls[231])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lbls[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_CR_vector(lbls, count_classes):\n",
    "  uniq = dict([(str(i),0) for i in range(count_classes)])\n",
    "  \n",
    "  for i in range(len(lbls)):\n",
    "    a,b = np.unique(lbls[i], return_counts=True)\n",
    "    for num in a:\n",
    "        uniq[str(num)] += 1\n",
    "  print(uniq)\n",
    "  return [round(uniq[k] / len(lbls),2) for k in uniq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_CR_vector(lbls, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = {mask_name: mask for mask_name, mask in zip(test, lbls)}\n",
    "scanner = HCScanner(lbls, 10)\n",
    "scanner.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner.hcv_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(path='/mnt/data/med_data/unbalanced_batches/batch_3'):\n",
    "    Ytrain = []\n",
    "    masks = glob.glob(path + '/masks/*.bmp')\n",
    "    masks.sort()\n",
    "    for mask_name in tqdm(masks):\n",
    "        mask = cv2.imread(mask_name)\n",
    "        Ytrain.append(mask[:,:,0])\n",
    "        if np.max(mask) >= 10:\n",
    "            print(np.max(mask), f' in image {mask_name} ')\n",
    "    return Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('2.bmp', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cv2.imread('/mnt/data/med_data/balanced_batches/bb_danil1/masks/527_0.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.resize(x, (1024,1024), interpolation=cv2.INTER_NEAREST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

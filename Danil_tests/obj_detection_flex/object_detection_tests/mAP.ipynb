{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ikilbas/anaconda3/lib/python3.7/site-packages/makiflow/base/maki_entities.py:143: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from makiflow.models.ssd.ssd_utils import jaccard_index\n",
    "from makiflow.metrics.od_utils import nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Builder.ssd_from_json('/home/ikilbas/work_dir/research/gradient_engineering/model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.tools import XmlParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = XmlParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5138/5138 [00:01<00:00, 2970.36it/s]\n"
     ]
    }
   ],
   "source": [
    "d = parser.parse_all_in_dict(source_path='/mnt/data/voc_test/VOCdevkit/VOC2012/Annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = dict([(key,0) for key,_ in name2class.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = copy.deepcopy(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d)):\n",
    "    info = d[i]\n",
    "    obj = info['objects']\n",
    "    for dic in obj:\n",
    "        count_train[dic['name']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aeroplane': 0,\n",
       " 'bottle': 0,\n",
       " 'motorbike': 0,\n",
       " 'train': 0,\n",
       " 'sheep': 0,\n",
       " 'person': 7326,\n",
       " 'bicycle': 0,\n",
       " 'boat': 0,\n",
       " 'pottedplant': 0,\n",
       " 'diningtable': 2,\n",
       " 'bird': 0,\n",
       " 'horse': 0,\n",
       " 'chair': 2,\n",
       " 'car': 0,\n",
       " 'sofa': 0,\n",
       " 'tvmonitor': 0,\n",
       " 'cow': 0,\n",
       " 'bus': 0,\n",
       " 'cat': 0,\n",
       " 'dog': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = copy.deepcopy(count)\n",
    "count_train = copy.deepcopy(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_set)):\n",
    "    info = test_set[i]\n",
    "    obj = info['objects']\n",
    "    for dic in obj:\n",
    "        count_test[dic['name']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_set)):\n",
    "    info = train_set[i]\n",
    "    obj = info['objects']\n",
    "    for dic in obj:\n",
    "        count_train[dic['name']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/testset_2007.json', 'w') as f:\n",
    "    json.dump(d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/classes.json', 'r') as f:\n",
    "    name2class = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_to_num = {}\n",
    "i = 1\n",
    "for cl in parser.classes:\n",
    "    class_name_to_num[cl] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2class = {'train': 1,\n",
    " 'tvmonitor': 2,\n",
    " 'aeroplane': 3,\n",
    " 'pottedplant': 4,\n",
    " 'diningtable': 5,\n",
    " 'cow': 6,\n",
    " 'sheep': 7,\n",
    " 'person': 8,\n",
    " 'horse': 9,\n",
    " 'motorbike': 10,\n",
    " 'bird': 11,\n",
    " 'car': 12,\n",
    " 'sofa': 13,\n",
    " 'boat': 14,\n",
    " 'cat': 15,\n",
    " 'chair': 16,\n",
    " 'bicycle': 17,\n",
    " 'bottle': 18,\n",
    " 'bus': 19,\n",
    " 'dog': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparator = DataPreparator(d, class_name_to_num, '/mnt/data/voc_test/VOCdevkit/VOC2012/JPEGImages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparator.load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparator.resize_images_and_bboxes((300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = preparator.normalize_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import makiflow as mf\n",
    "mf.set_main_gpu(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.set_session(tf.Session())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/ikilbas/work_dir/research/gradient_engineering/object_detection/ssd_pipeline/reg_test/focal.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs[128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(imgs)):\n",
    "    # preds = [confidences, locs]\n",
    "    # `confidences` shape is [batch_sz, total_predictions, num_classes]\n",
    "    # `locs` shape is [batch_sz, total_predictions, 4]\n",
    "    preds += [model.predict([imgs[i]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.metrics.od_metrics import mAP_maki_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP_maki_supported(preds, iou_threshold=0.5, conf_threshold=0.5, test_dict=d, name2class=name2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds = []\n",
    "for pred in preds:\n",
    "    # bboxes, classes, confidences\n",
    "    # `bboxes` is a list of ndarrays\n",
    "    # `classes` is a list of ints\n",
    "    # `confidences` is a list of floats\n",
    "    filtered_preds += [nms(pred[1][0], pred[0][0], conf_threshold=0.5, iou_threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "([np.array([0, 0, 0, 0], dtype=np.float32)], [-1], [0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_filtered_preds(filtered_preds):\n",
    "    # Deletes empty predictions\n",
    "    сleared = []\n",
    "    for filtered_pred in filtered_preds:\n",
    "        if len(filtered_pred[0]) != 0:\n",
    "            сleared += [filtered_pred]\n",
    "        else:\n",
    "            сleared += [([np.array([1, 1, 1, 1], dtype=np.float32)], [-1], [0.0])]\n",
    "    return сleared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds = clear_filtered_preds(filtered_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_nms_result(filtered_pred):\n",
    "    boxes = np.vstack(filtered_pred[0])\n",
    "    classes = np.array(filtered_pred[1])\n",
    "    confs = np.array(filtered_pred[2])\n",
    "    return boxes, classes, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes = []\n",
    "pred_cs = []\n",
    "pred_ps = []\n",
    "for filtered_pred in filtered_preds:\n",
    "    boxes, classes, confs = merge_nms_result(filtered_pred)\n",
    "    pred_boxes += [boxes]\n",
    "    pred_cs += [classes]\n",
    "    pred_ps += [confs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dicts(data_dicts, name2class):\n",
    "    # `data_dict` is a list of dictionaries.\n",
    "    # The dictionaries contain several fields:\n",
    "    # 'filename' - name of the file;\n",
    "    # 'folder' - name of the folder;\n",
    "    # 'size' - size of the pictire: (channels, width, height);\n",
    "    # 'objects' - list of dictionaries that contain info about the \n",
    "    # objects on the image:\n",
    "    # [{'name' : 'object_name', 'box': [x1, x2, x3, x4]}]\n",
    "    true_boxes = []\n",
    "    true_classes = []\n",
    "    for image_dict in data_dicts:\n",
    "        # Collect the bboxes and stack them together\n",
    "        image_boxes = []\n",
    "        image_classes = []\n",
    "        for object_dict in image_dict['objects']:\n",
    "            image_boxes += [np.array(object_dict['box'], dtype=np.float32)]\n",
    "            image_classes += [name2class[object_dict['name']]]\n",
    "        true_boxes += [np.vstack(image_boxes)]\n",
    "        true_classes += [np.array(image_classes, dtype=np.int32)]\n",
    "    return true_boxes, true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_boxes, true_classes = parse_dicts(d, name2class=name2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
    "    mpre = np.concatenate(([0.0], precision, [0.0]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tps(pred_boxes, pred_classes, true_boxes, true_classes, iou_th=0.5):\n",
    "    \"\"\"\n",
    "    Computes True Positives for the given predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_boxes : ndarray\n",
    "        Array of the predicted bounding boxes.\n",
    "    pred_classes : ndarray\n",
    "        Array of the predicted classes for `pred_boxes`.\n",
    "    true_boxes : ndarray\n",
    "        Array of the true bouding boxes.\n",
    "    true_classes : ndarray\n",
    "        Array of the true classes for `true_boxes`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Array of shape [len(pred_boxes)] where ith element equals 1 if ith bbox is correct\n",
    "        and 0 otherwise.\n",
    "        \n",
    "    \"\"\"\n",
    "    tps = np.zeros(len(pred_boxes))\n",
    "    for i, true_box in enumerate(true_boxes):\n",
    "        ious = jaccard_index(pred_boxes, np.array([true_box] * len(pred_boxes)))\n",
    "        iou_match = ious > iou_th\n",
    "        class_match = pred_classes == true_classes[i]\n",
    "        tp_indices = iou_match * class_match\n",
    "        if np.max(tp_indices) != False:\n",
    "            tps[np.argmax(tp_indices)] = 1\n",
    "    return tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ap_per_class(tp, conf, pred_cls, target_cls):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n",
    "    # Arguments\n",
    "        tp:    True positives (list).\n",
    "        conf:  Objectness value from 0-1 (list).\n",
    "        pred_cls: Predicted object classes (list).\n",
    "        target_cls: True object classes (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort by objectness\n",
    "    i = np.argsort(-conf)\n",
    "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
    "\n",
    "    # Find unique classes\n",
    "    unique_classes = np.unique(target_cls)\n",
    "\n",
    "    # Create Precision-Recall curve and compute AP for each class\n",
    "    ap, p, r = [], [], []\n",
    "    for c in tqdm.tqdm(unique_classes, desc=\"Computing AP\"):\n",
    "        i = pred_cls == c\n",
    "        n_gt = (target_cls == c).sum()  # Number of ground truth objects\n",
    "        n_p = i.sum()  # Number of predicted objects\n",
    "\n",
    "        if n_p == 0 and n_gt == 0:\n",
    "            continue\n",
    "        elif n_p == 0 or n_gt == 0:\n",
    "            ap.append(0)\n",
    "            r.append(0)\n",
    "            p.append(0)\n",
    "        else:\n",
    "            # Accumulate FPs and TPs\n",
    "            fpc = (1 - tp[i]).cumsum()\n",
    "            tpc = (tp[i]).cumsum()\n",
    "\n",
    "            # Recall\n",
    "            recall_curve = tpc / (n_gt + 1e-16)\n",
    "            r.append(recall_curve[-1])\n",
    "\n",
    "            # Precision\n",
    "            precision_curve = tpc / (tpc + fpc)\n",
    "            p.append(precision_curve[-1])\n",
    "\n",
    "            # AP from recall-precision curve\n",
    "            ap.append(compute_ap(recall_curve, precision_curve))\n",
    "\n",
    "    # Compute F1 score (harmonic mean of precision and recall)\n",
    "    p, r, ap = np.array(p), np.array(r), np.array(ap)\n",
    "    f1 = 2 * p * r / (p + r + 1e-16)\n",
    "\n",
    "    return p, r, ap, f1, unique_classes.astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP(pred_boxes, pred_cs, pred_ps, true_boxes, true_cs, iou_th=0.5):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_boxes : list\n",
    "        List of ndarrays of shape [total_preds, 4]. Contains predicted bboxes for one image.\n",
    "    pred_cs : list\n",
    "        List of ndarrays of shape [total_preds]. Contains classes for `pred_boxes`.\n",
    "    pred_ps : list\n",
    "        List of ndarrays of shape [total_preds]. Contains confidences for `pred_cs`.\n",
    "    true_boxes : list\n",
    "        List of ndarrays of shape [total_preds, 4]. Contains true bboxes for one image.\n",
    "    true_cs : list\n",
    "        List of ndarrays of shape [total_preds]. Contains classes for `true_boxes`.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_images = len(pred_boxes)\n",
    "    all_tps = []\n",
    "    for i in range(num_images):\n",
    "        all_tps += [compute_tps(\n",
    "            pred_boxes=pred_boxes[i],\n",
    "            pred_classes=pred_cs[i],\n",
    "            true_boxes=true_boxes[i],\n",
    "            true_classes=true_cs[i],\n",
    "            iou_th=iou_th\n",
    "        )]\n",
    "        \n",
    "    all_tps = np.concatenate(all_tps, axis=0)\n",
    "    pred_cs = np.concatenate(pred_cs, axis=0)\n",
    "    pred_ps = np.concatenate(pred_ps, axis=0)\n",
    "    true_cs = np.concatenate(true_cs, axis=0)\n",
    "    \n",
    "    p, r, ap, f1, unique_classes = ap_per_class(\n",
    "        tp=all_tps,\n",
    "        conf=pred_ps,\n",
    "        pred_cls=pred_cs,\n",
    "        target_cls=true_cs\n",
    "    )\n",
    "    return p, r, ap, f1, unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, ap, f1, unique_classes = mAP(pred_boxes, pred_cs, pred_ps, true_boxes, true_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [num_predictions]\n",
    "# preds = [[conf, locs]]\n",
    "# conf = [batch_sz, num_classes]\n",
    "len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_preds = []\n",
    "for pred in preds:\n",
    "    splitted_preds += [[p, l] for p, l in zip(pred[0], pred[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_preds[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(splitted_preds)):\n",
    "    splitted_preds[i][0], splitted_preds[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[nms(preds[0][1][0], preds[0][0][0], conf_threshold=0.5, iou_threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the prediction array \n",
    "filtered_preds = []\n",
    "for pred in tqdm.tqdm(splitted_preds):\n",
    "    # bboxes, classes, confidences\n",
    "    # `bboxes` is a list of ndarrays\n",
    "    # `classes` is a list of ints\n",
    "    # `confidences` is a list of floats\n",
    "    filtered_preds += [nms(pred[1], pred[0], conf_threshold=0.5, iou_threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds_ = []\n",
    "for confidences, localisations in preds:\n",
    "    for image_confs, image_locs in zip(confidences, localisations):\n",
    "        # bboxes, classes, confidences\n",
    "        # `bboxes` is a list of ndarrays\n",
    "        # `classes` is a list of ints\n",
    "        # `confidences` is a list of floats\n",
    "        filtered_preds_ += [nms(image_locs , image_confs, conf_threshold=0.5, iou_threshold=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_preds = []\n",
    "for confidences, localisations in preds:\n",
    "    for image_confs, image_locs in zip(confidences, localisations):\n",
    "        # bboxes, classes, confidences\n",
    "        # `bboxes` is a list of ndarrays\n",
    "        # `classes` is a list of ints\n",
    "        # `confidences` is a list of floats\n",
    "        filtered_preds += [nms(image_locs , image_confs, conf_threshold=0.5, iou_threshold=0.5)]\n",
    "# Clear the NMS results from empty predictions\n",
    "filtered_preds = clear_filtered_preds(filtered_preds)\n",
    "# Convert NMS results to separate lists of numpy arrays\n",
    "pred_boxes = []\n",
    "pred_cs = []\n",
    "pred_ps = []\n",
    "for filtered_pred in filtered_preds:\n",
    "    boxes, classes, confs = merge_nms_result(filtered_pred)\n",
    "    pred_boxes += [boxes]\n",
    "    pred_cs += [classes]\n",
    "    pred_ps += [confs]\n",
    "\n",
    "# PROCESS THE GROUND TRUE LABELS\n",
    "true_boxes, true_classes = parse_dicts(d, name2class=name2class)\n",
    "\n",
    "# COMPUTE THE mAP\n",
    "p, r, ap, f1, unique_classes = mAP(\n",
    "    pred_boxes,\n",
    "    pred_cs,\n",
    "    pred_ps,\n",
    "    true_boxes,\n",
    "    true_classes,\n",
    "    iou_th=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, ap, f1, unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
